{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Global config variables\n",
    "num_steps = 10 # number of truncated backprop steps ('n' in the discussion above)\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 4\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "# adapted from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "\n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholders\n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "\"\"\"\n",
    "RNN Inputs\n",
    "\"\"\"\n",
    "\n",
    "# Turn our x placeholder into a list of one-hot tensors:\n",
    "# rnn_inputs is a list of num_steps tensors with shape [batch_size, num_classes]\n",
    "x_one_hot = tf.one_hot(x, num_classes)\n",
    "# x ==> (200, 5)\n",
    "# x_one_hot ==> (200, 5, 2)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1)\n",
    "# run_inputs ==> (200, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 解释unstack的意思\n",
    "这里使用unstack是为了把一个batch的200句话平行输入RNN.\n",
    "\n",
    "步骤如下:\n",
    "1. 首先把batch_size定义为200, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### tf.unstack(value, axis=0)\n",
    "what is the meaning of axis?\n",
    "1. function: unstack the tensor from rank R to rank (R-1)\n",
    "    - in the example above, the rank R of x_one_hot is 3, rnn_inputs'rank is 2.\n",
    "    - the axis is used for value.shape[axis]\n",
    "2. why do it use unstack to deminish the data?\n",
    "    - from the document we can know that there should be 5 tensors in run_inputs. But the shape is only (200, 2), why?\n",
    "    - refer to the np.unstack()\n",
    "    - There should be 5 (200, 2) matrixs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definition of rnn_cell\n",
    "\n",
    "This is very similar to the __call__ method on Tensorflow's BasicRNNCell. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py#L95\n",
    "\"\"\"\n",
    "with tf.variable_scope('rnn_cell'):\n",
    "    W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "    b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "def rnn_cell(rnn_input, state):\n",
    "    with tf.variable_scope('rnn_cell', reuse=True):\n",
    "        W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "        b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "这个操作实现的就是下面这个运算\n",
    "$(x @ s) \\times w + b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### tf.concat & tf.stack\n",
    "1. 共同点: 这两个函数都是用来reshape tensor的.\n",
    "2. 不同点:\n",
    "    - concat 把拥有一个共同维度的数组按照该维度组合.\n",
    "    - stack 可以把一个大于2维的数组按照一个指定维度来展开.\n",
    "3. 两者之间的转换如何举例?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adding rnn_cells to graph\n",
    "\n",
    "This is a simplified version of the \"static_rnn\" function from Tensorflow's api. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn.py#L41\n",
    "Note: In practice, using \"dynamic_rnn\" is a better choice that the \"static_rnn\":\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py#L390\n",
    "\"\"\"\n",
    "state = init_state\n",
    "rnn_outputs = [] # A list of states based on the input size.\n",
    "for rnn_input in rnn_inputs: # run_inputs ==> (200, 2) * 5 list\n",
    "    state = rnn_cell(rnn_input, state)\n",
    "    rnn_outputs.append(state) \n",
    "final_state = rnn_outputs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "这个state 是一个自己定义维度的一个向量, 对于每一个batch 都有 *一系列* 的states和它对应.\n",
    "$$state \\in R^{batch\\_size \\times num\\_steps}$$\n",
    "### TODO: state向量的维度是多少比较合适呢?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predictions, loss, training step\n",
    "\n",
    "Losses is similar to the \"sequence_loss\"\n",
    "function from Tensorflow's API, except that here we are using a list of 2D tensors, instead of a 3D tensor. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/loss.py#L30\n",
    "\"\"\"\n",
    "\n",
    "#logits and predictions\n",
    "with tf.variable_scope('softmax', reuse=None):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], \n",
    "                        initializer=tf.constant_initializer(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "# logits ==> (time_step, batch_size, num_classes)\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "# predictions ==> logits.shape\n",
    "# Turn our y placeholder into a list of labels\n",
    "y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "# y_as_list ==> 5 * (200, 2)\n",
    "#losses and train_step\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) for \\\n",
    "          logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TODO: what is the difference between the two w and b? Are they the same, or they are different?\n",
    "\n",
    "\n",
    "The above is calculating the states with the next input, and store into a list named _prediction_ .\n",
    "$$state \\times w + b $$\n",
    "\n",
    "- the size of each variables.\n",
    "$$ w\\in R^{d \\times (n+s)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 关于 tf.variable_scope(name) \n",
    "scope的作用类似于一个命名管理器.\n",
    "\n",
    "不同scope下面的变量可以使用相同的名字."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train the network\n",
    "\"\"\"\n",
    "\n",
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                  feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 250 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0\n",
      "Average loss at step 100 for last 250 steps: 0.631549962163\n",
      "Average loss at step 200 for last 250 steps: 0.529166456461\n",
      "Average loss at step 300 for last 250 steps: 0.520547061563\n",
      "Average loss at step 400 for last 250 steps: 0.51986587435\n",
      "\n",
      "EPOCH 1\n",
      "Average loss at step 100 for last 250 steps: 0.522457573414\n",
      "Average loss at step 200 for last 250 steps: 0.51359729588\n",
      "Average loss at step 300 for last 250 steps: 0.513097512722\n",
      "Average loss at step 400 for last 250 steps: 0.513096005023\n",
      "\n",
      "EPOCH 2\n",
      "Average loss at step 100 for last 250 steps: 0.517191099823\n",
      "Average loss at step 200 for last 250 steps: 0.51189797014\n",
      "Average loss at step 300 for last 250 steps: 0.510683863163\n",
      "Average loss at step 400 for last 250 steps: 0.510342955589\n",
      "\n",
      "EPOCH 3\n",
      "Average loss at step 100 for last 250 steps: 0.517033561468\n",
      "Average loss at step 200 for last 250 steps: 0.511458417177\n",
      "Average loss at step 300 for last 250 steps: 0.509486623704\n",
      "Average loss at step 400 for last 250 steps: 0.509473537505\n",
      "\n",
      "EPOCH 4\n",
      "Average loss at step 100 for last 250 steps: 0.517186211944\n",
      "Average loss at step 200 for last 250 steps: 0.511897653937\n",
      "Average loss at step 300 for last 250 steps: 0.508820809126\n",
      "Average loss at step 400 for last 250 steps: 0.509945710301\n",
      "\n",
      "EPOCH 5\n",
      "Average loss at step 100 for last 250 steps: 0.516182478964\n",
      "Average loss at step 200 for last 250 steps: 0.508866322339\n",
      "Average loss at step 300 for last 250 steps: 0.510075215101\n",
      "Average loss at step 400 for last 250 steps: 0.511404285133\n",
      "\n",
      "EPOCH 6\n",
      "Average loss at step 100 for last 250 steps: 0.517243795991\n",
      "Average loss at step 200 for last 250 steps: 0.508991094828\n",
      "Average loss at step 300 for last 250 steps: 0.509814697504\n",
      "Average loss at step 400 for last 250 steps: 0.510982448459\n",
      "\n",
      "EPOCH 7\n",
      "Average loss at step 100 for last 250 steps: 0.515572998822\n",
      "Average loss at step 200 for last 250 steps: 0.509943111241\n",
      "Average loss at step 300 for last 250 steps: 0.509420209825\n",
      "Average loss at step 400 for last 250 steps: 0.509848531187\n",
      "\n",
      "EPOCH 8\n",
      "Average loss at step 100 for last 250 steps: 0.516507469416\n",
      "Average loss at step 200 for last 250 steps: 0.510209859312\n",
      "Average loss at step 300 for last 250 steps: 0.509729736447\n",
      "Average loss at step 400 for last 250 steps: 0.50697145313\n",
      "\n",
      "EPOCH 9\n",
      "Average loss at step 100 for last 250 steps: 0.515244738758\n",
      "Average loss at step 200 for last 250 steps: 0.508090243638\n",
      "Average loss at step 300 for last 250 steps: 0.508006373048\n",
      "Average loss at step 400 for last 250 steps: 0.510823069811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3c4c65f080>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkkb+P60Ed5sivgv0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3c67c09f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = train_network(num_steps=10, state_size=4, num_epochs=10)\n",
    "plt.plot(training_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "The author said this is the first dependency.\n",
    "But why?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
