{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Global config variables\n",
    "num_steps = 5 # number of truncated backprop steps ('n' in the discussion above)\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 4\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "# adapted from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "\n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholders\n",
    "\"\"\"\n",
    "\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "\"\"\"\n",
    "RNN Inputs\n",
    "\"\"\"\n",
    "\n",
    "# Turn our x placeholder into a list of one-hot tensors:\n",
    "# rnn_inputs is a list of num_steps tensors with shape [batch_size, num_classes]\n",
    "x_one_hot = tf.one_hot(x, num_classes)\n",
    "# x ==> (200, 5)\n",
    "# x_one_hot ==> (200, 5, 2)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1)\n",
    "# run_inputs ==> (200, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 解释unstack的意思\n",
    "这里使用unstack是为了把一个batch的200句话平行输入RNN.\n",
    "\n",
    "步骤如下:\n",
    "1. 首先把batch_size定义为200, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### tf.unstack(value, axis=0)\n",
    "what is the meaning of axis?\n",
    "1. function: unstack the tensor from rank R to rank (R-1)\n",
    "    - in the example above, the rank R of x_one_hot is 3, rnn_inputs'rank is 2.\n",
    "    - the axis is used for value.shape[axis]\n",
    "2. why do it use unstack to deminish the data?\n",
    "    - from the document we can know that there should be 5 tensors in run_inputs. But the shape is only (200, 2), why?\n",
    "    - refer to the np.unstack()\n",
    "    - There should be 5 (200, 2) matrixs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definition of rnn_cell\n",
    "\n",
    "This is very similar to the __call__ method on Tensorflow's BasicRNNCell. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py#L95\n",
    "\"\"\"\n",
    "with tf.variable_scope('rnn_cell'):\n",
    "    W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "    b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "def rnn_cell(rnn_input, state):\n",
    "    with tf.variable_scope('rnn_cell', reuse=True):\n",
    "        W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "        b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "这个操作实现的就是下面这个运算\n",
    "$(x @ s) \\times w + b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### tf.concat & tf.stack\n",
    "1. 共同点: 这两个函数都是用来reshape tensor的.\n",
    "2. 不同点:\n",
    "    - concat 把拥有一个共同维度的数组按照该维度组合.\n",
    "    - stack 可以把一个大于2维的数组按照一个指定维度来展开.\n",
    "3. 两者之间的转换如何举例?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adding rnn_cells to graph\n",
    "\n",
    "This is a simplified version of the \"static_rnn\" function from Tensorflow's api. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn.py#L41\n",
    "Note: In practice, using \"dynamic_rnn\" is a better choice that the \"static_rnn\":\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py#L390\n",
    "\"\"\"\n",
    "state = init_state\n",
    "rnn_outputs = [] # A list of states based on the input size.\n",
    "for rnn_input in rnn_inputs: # run_inputs ==> (200, 2) * 5 list\n",
    "    state = rnn_cell(rnn_input, state)\n",
    "    rnn_outputs.append(state) \n",
    "final_state = rnn_outputs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "这个state 是一个自己定义维度的一个向量, 对于每一个batch 都有 *一系列* 的states和它对应.\n",
    "$$state \\in R^{batch\\_size \\times num\\_steps}$$\n",
    "### TODO: state向量的维度是多少比较合适呢?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predictions, loss, training step\n",
    "\n",
    "Losses is similar to the \"sequence_loss\"\n",
    "function from Tensorflow's API, except that here we are using a list of 2D tensors, instead of a 3D tensor. See:\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/loss.py#L30\n",
    "\"\"\"\n",
    "\n",
    "#logits and predictions\n",
    "with tf.variable_scope('softmax', reuse=None):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], \n",
    "                        initializer=tf.constant_initializer(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "# logits ==> (time_step, batch_size, num_classes)\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "# predictions ==> logits.shape\n",
    "# Turn our y placeholder into a list of labels\n",
    "y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "# y_as_list ==> 5 * (200, 2)\n",
    "#losses and train_step\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) for \\\n",
    "          logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TODO: what is the difference between the two w and b? Are they the same, or they are different?\n",
    "\n",
    "\n",
    "The above is calculating the states with the next input, and store into a list named _prediction_ .\n",
    "$$state \\times w + b $$\n",
    "\n",
    "- the size of each variables.\n",
    "$$ w\\in R^{d \\times (n+s)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 关于 tf.variable_scope(name) \n",
    "scope的作用类似于一个命名管理器.\n",
    "\n",
    "不同scope下面的变量可以使用相同的名字."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train the network\n",
    "\"\"\"\n",
    "\n",
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                  feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step,\n",
    "                              \"for last 250 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0\n",
      "Average loss at step 100 for last 250 steps: 0.649300990105\n",
      "Average loss at step 200 for last 250 steps: 0.591710200906\n",
      "Average loss at step 300 for last 250 steps: 0.519892680645\n",
      "Average loss at step 400 for last 250 steps: 0.522780284286\n",
      "Average loss at step 500 for last 250 steps: 0.523327998221\n",
      "Average loss at step 600 for last 250 steps: 0.521892652512\n",
      "Average loss at step 700 for last 250 steps: 0.521415250003\n",
      "Average loss at step 800 for last 250 steps: 0.520249815881\n",
      "Average loss at step 900 for last 250 steps: 0.521270725429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f96ce730518>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96ceb36ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = train_network(1,num_steps)\n",
    "plt.plot(training_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "The author said this is the first dependency.\n",
    "But why?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
